{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "QTM350_BLOG",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rO_GPe8kf_h7"
      },
      "source": [
        "## The Application of AWS Rekognition to the Identification of Missing Children\n",
        "### Introduction and Motivation\n",
        "\n",
        "  Kidnappings and missing children are serious problems within our society. Services such as the child abduction alert system and missing people website may help parents find their missing children, yet there is the possibility that some of the kids cannot be found. According to statistics from the Federal Bureau of Investigation (FBI), in 2020, 365,348 missing children cases were registered, and in 2019, there were 421,394 (\"Key Facts\", 2021). About 89% to 92% percent of all missing persons are found either dead or alive, which leaves about 10% unresolved cases and the parents suffer from huge losses, hoping for finding their children in the future. However, after many years, it might be very hard to recognize a person. To find if there is any possibility to alleviate this worldwide problem with the aid of AWS Rekognition, we designed our project, which explores to what extent that this tool can figure out the similarities between the images of the same person as a child and after turning into an adult.\n",
        "\n",
        "### The Reason Why We Use Amazon Rekognition\n",
        "\n",
        "AWS Rekognition generates data from a picture, summarizing information about objects, backgrounds, human faces, facial expressions and so on. When given two photos of the same person, it gives the possibility of similarity, which is usually high, accurately judges that they present the same person. However, there is one challenge when dealing with the missing children – they grow. If they cannot be spotted quickly, their appearances may change. To determine whether AWS Rekognition is useful on the missing children cases, we want to explore this technology and find answering the following questions: first, does AWS Rekognition match the face of a grown-up with his or her childhood photo? Second, how accurate is AWS Rekognition when a part of the face is hidden, or the individuals’ facial structures have changed due to maturing? Will the accuracy decrease with the increasing age difference? Third, are there any possible ways to improve this tool’s accuracy?\n",
        "\n",
        "We hypothesized that AWS Rekognition can recognize the same person at different ages. However, since people’s facial features can drastically change after years, we also expect the accuracy of results may decrease if the age difference between the two pictures of the same individual is large. So, as the first part of our project, we selected 5 sets of pictures of 5 people (3 males and 2 females). Three of them are gathered from a news website under the title \"This Family Took The Same Picture Every Year For Over Two Decades\" and the rest two are gathered from two research published by Dr. Reynolds and Dr. Zhao. All data sources are publically available online without the problem of copyright. We tried to use photos of group members as our data source we could not gather photos from long before. Among those five sets of pictures, we are going to test similarity within groups to see how well AWS Rekognition detecting the same person of different ages. One picture that is similar in color, gesture, race, and facial expression was added as a control group for each set so we are sure that the similarity yield by the testing is not due to those attributes. Next, we further call the age detection and age extract function in AWS Rekognition so that we get to know AWS's estimate for the age of people in the picture. If AWS Rekognition is proved to have high accuracy on such tests, looking for missing kids might be more viable since age is one of few attributes that people looking for missing people know for sure and won't change.\n",
        "\n",
        "![Data Example](https://github.com/AlisiaTian/SP2021QTM350/blob/main/blog/01.png?raw=true)\n",
        "\n",
        "### How It Works\n",
        "![Architecture](https://github.com/AlisiaTian/SP2021QTM350/blob/main/blog/02.jpg?raw=true)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "catholic-wallpaper"
      },
      "source": [
        "To start with, we will build a Amazon S3 bucket. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "economic-monitor",
        "outputId": "682a7c09-244d-4eea-8058-6619fec70081"
      },
      "source": [
        "# make a bucket\n",
        "!aws s3 mb s3://image-api-example-finalversion"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "make_bucket failed: s3://image-api-example-finalversion An error occurred (BucketAlreadyExists) when calling the CreateBucket operation: The requested bucket name is not available. The bucket namespace is shared by all users of the system. Please select a different name and try again.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "suffering-restoration"
      },
      "source": [
        "# Import important package\n",
        "import boto3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "given-spyware"
      },
      "source": [
        " Then we need to loop through the images in the bucket. To do this we will first make a Python list of all the images in the bucket. First we use boto3 to make an instance of an object s3_resource that will allow us to communicate with S3.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hearing-gnome",
        "outputId": "ec07914a-d58f-4ce7-e77c-728871520091"
      },
      "source": [
        "s3_resource = boto3.resource('s3')\n",
        "my_bucket = s3_resource.Bucket('image-api-example-finalversion')\n",
        "summaries = my_bucket.objects.all()\n",
        "summaries"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "s3.Bucket.objectsCollection(s3.Bucket(name='image-api-example-finalversion'), s3.ObjectSummary)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "royal-steam"
      },
      "source": [
        "We create a list called images, and using loop to add the name of the image into the list for later usage"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "alive-petersburg"
      },
      "source": [
        "images = []\n",
        "for image in summaries:\n",
        "    images.append(image.key)\n",
        "images\n",
        "images"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "interesting-design"
      },
      "source": [
        "Then we create an create an instance client of the client object in the boto3 package for rekognition.It will allow use to communicate and make requests to the Rekognition service using Python."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "black-distribution"
      },
      "source": [
        "# Create an instance client of the client object in the boto3 package for rekognition\n",
        "\n",
        "client=boto3.client('rekognition')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eleven-amount"
      },
      "source": [
        "# Dataset 1 "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "flush-potential"
      },
      "source": [
        "In the below chunck of code, we import two important package numpy and pandas into the enviroment for later usage, create an empty dataset called df using pd, use boto3 to make an instance of an object s3_resource that will allow us to communicate with S3, and loop thorugh the summaries bucket and add the images names into the df dataframe under the column \"Name\"\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "consolidated-label"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "df = pd.DataFrame()\n",
        "s3_resource = boto3.resource('s3')\n",
        "my_bucket = s3_resource.Bucket('image-api-example-finalversion')\n",
        "summaries = my_bucket.objects.all()\n",
        "image_names = [image.key for image in summaries]\n",
        "df[\"Name\"] = image_names"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "coastal-practice"
      },
      "source": [
        "We also make a new dataframe called qf using pd and add the images names into the df dataframe under the column \"Name\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "australian-butler"
      },
      "source": [
        "qf = pd.DataFrame()\n",
        "qf[\"Name\"] = image_names"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "silent-parker"
      },
      "source": [
        "We then create a list called small_name and add all the image names into the list, and use it latter for the column names in the loop function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "natural-beaver"
      },
      "source": [
        "small_name = [\"Similarity-child-91\",\"Similarity-child-92\",\"Similarity-child-93\",\"Similarity-child-94\",\"Similarity-child-95\",\"Similarity-child-96\",\"Similarity-child-97\",\"Similarity-child-98\",\"Similarity-child-99\",\"Similarity-child-00\",\"Similarity-child-02\",\"Similarity-child-03\",\"Similarity-child-04\",\"Similarity-child-05\",\"Similarity-child-06\",\"Similarity-child-07\",\"Similarity-child-08\",\"Similarity-child-09\",\"Similarity-child-10\",\"Similarity-child-11\",\"Similarity-child-12\",\"Similarity-child-13\",\n",
        "              \"Similarity-female-91\",\"Similarity-female-92\",\"Similarity-female-93\",\"Similarity-female-94\",\"Similarity-female-95\",\"Similarity-female-96\",\"Similarity-female-97\",\"Similarity-female-98\",\"Similarity-female-99\",\"Similarity-female-00\",\"Similarity-female-02\",\"Similarity-female-03\",\"Similarity-female-04\",\"Similarity-female-05\",\"Similarity-female-06\",\"Similarity-female-07\",\"Similarity-female-08\",\"Similarity-female-09\",\"Similarity-female-10\",\"Similarity-female-11\",\"Similarity-female-12\",\"Similarity-female-13\",\n",
        "             \"Similarity-male-91\",\"Similarity-male-92\",\"Similarity-male-93\",\"Similarity-male-94\",\"Similarity-male-95\",\"Similarity-male-96\",\"Similarity-male-97\",\"Similarity-male-98\",\"Similarity-male-99\",\"Similarity-male-00\",\"Similarity-male-02\",\"Similarity-male-03\",\"Similarity-male-04\",\"Similarity-male-05\",\"Similarity-male-06\",\"Similarity-male-07\",\"Similarity-male-08\",\"Similarity-male-09\",\"Similarity-male-10\",\"Similarity-male-11\",\"Similarity-male-12\",\"Similarity-male-13\"]\n",
        "\n",
        "big_name = [\"range-child-91\",\"range-child-92\",\"range-child-93\",\"range-child-94\",\"range-child-95\",\"range-child-96\",\"range-child-97\",\"range-child-98\",\"range-child-99\",\"range-child-00\",\"range-child-02\",\"range-child-03\",\"range-child-04\",\"range-child-05\",\"range-child-06\",\"range-child-07\",\"range-child-08\",\"range-child-09\",\"range-child-10\",\"range-child-11\",\"range-child-12\",\"range-child-13\",\n",
        "              \"Similarity-female-91\",\"Similarity-female-92\",\"Similarity-female-93\",\"Similarity-female-94\",\"Similarity-female-95\",\"Similarity-female-96\",\"Similarity-female-97\",\"Similarity-female-98\",\"Similarity-female-99\",\"Similarity-female-00\",\"Similarity-female-02\",\"Similarity-female-03\",\"Similarity-female-04\",\"Similarity-female-05\",\"Similarity-female-06\",\"Similarity-female-07\",\"Similarity-female-08\",\"Similarity-female-09\",\"Similarity-female-10\",\"Similarity-female-11\",\"Similarity-female-12\",\"Similarity-female-13\",\n",
        "             \"Similarity-male-91\",\"Similarity-male-92\",\"Similarity-male-93\",\"Similarity-male-94\",\"Similarity-male-95\",\"Similarity-male-96\",\"Similarity-male-97\",\"Similarity-male-98\",\"Similarity-male-99\",\"Similarity-male-00\",\"Similarity-male-02\",\"Similarity-male-03\",\"Similarity-male-04\",\"Similarity-male-05\",\"Similarity-male-06\",\"Similarity-male-07\",\"Similarity-male-08\",\"Similarity-male-09\",\"Similarity-male-10\",\"Similarity-male-11\",\"Similarity-male-12\",\"Similarity-male-13\"]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "grateful-retreat"
      },
      "source": [
        "For this chunk, we first create a constant i = 0 for later usage in the loop.Then we make a loop function. Inside the loop function we define a function called extract_similarity to extract the similarity value for each set using the compare_faces function in the rekognition. After we got the image_score we store it into the df dataframe and stored it under the column name small_name at the i position."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "regulated-ministry"
      },
      "source": [
        "i = 0\n",
        "for photo in images:\n",
        "    def extract_similarity(image):\n",
        "        try:\n",
        "            comparison = client.compare_faces(SourceImage={'S3Object':{'Bucket':\"image-api-example-finalversion\",'Name':photo}}, TargetImage={'S3Object':{'Bucket':\"image-api-example-finalversion\",'Name':image}})\n",
        "            face_match = comparison['FaceMatches']\n",
        "            image_score = face_match[0]['Similarity'] \n",
        "        except:\n",
        "            image_score = np.nan\n",
        "        return image_score\n",
        "    df[small_name[i]] = [extract_similarity(name) for name in df[\"Name\"]]\n",
        "    i = i + 1\n",
        "    print(i)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "naked-brick"
      },
      "source": [
        "Here we define a function called extract_Age to extract the age range value for each image using the detect_faces function in the rekognition."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "similar-hebrew"
      },
      "source": [
        "def extract_age(image):\n",
        "    try:\n",
        "        comparison = client.detect_faces(Image={'S3Object':{'Bucket':\"image-api-example-finalversion\",'Name':image}}, Attributes = [\"ALL\"])\n",
        "        age_range = comparison[\"FaceDetails\"][0][\"AgeRange\"] \n",
        "    except:\n",
        "        age_range = np.nan\n",
        "    return age_range"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "seeing-member"
      },
      "source": [
        "After we got the age_range we store it into the df dataframe and stored it under the column name \"Age_range\"."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "super-violin"
      },
      "source": [
        "df[\"Age_Range\"] = [extract_age(name) for name in qf[\"Name\"]]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "regulation-mouse"
      },
      "source": [
        "Finally, we output the result to a csv file called Newresult.csv"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "still-asset",
        "outputId": "7abf12c8-0041-4a4e-a235-44cc3fb797a7"
      },
      "source": [
        "df.to_csv(\"Newresult.csv\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'df' is not defined",
          "traceback": [
            "\u001b[0;31m\u001b[0m",
            "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-78d27406ff30>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Newresult.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "different-syracuse"
      },
      "source": [
        "# Dataset 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "knowing-destruction"
      },
      "source": [
        "First, make an Amazon S3 bucket"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "monetary-survivor",
        "outputId": "0954fa8e-a905-4e58-e14d-884d1f8a2232"
      },
      "source": [
        "!aws s3 mb s3://image-api-example-finalversion2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "make_bucket: image-api-example-finalversion2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "endless-receptor"
      },
      "source": [
        "Then we need to loop through the images in the bucket. To do this we will first make a Python list of all the images in the bucket.\n",
        "First we use boto3 to make an instance of an object s3_resource that will allow us to communicate with S3.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "international-skating",
        "outputId": "15b56b99-270d-49cd-f2da-edc77cb7df9d"
      },
      "source": [
        "s3_resource = boto3.resource('s3')\n",
        "my_bucket = s3_resource.Bucket('image-api-example-finalversion2')\n",
        "summaries = my_bucket.objects.all()\n",
        "summaries"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "s3.Bucket.objectsCollection(s3.Bucket(name='image-api-example-finalversion2'), s3.ObjectSummary)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "advisory-perfume"
      },
      "source": [
        "We create a list called images, and using loop to add the name of the image into the list for later usage"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "likely-annotation",
        "outputId": "d7a93bca-04ce-4837-97a2-674d9dc73a6e"
      },
      "source": [
        "images = []\n",
        "for image in summaries:\n",
        "    images.append(image.key)\n",
        "images\n",
        "images"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[u'1age10.png',\n",
              " u'1age16.png',\n",
              " u'1age3.png',\n",
              " u'1age4.png',\n",
              " u'1age6.png',\n",
              " u'1age8.png',\n",
              " u'1age9.png',\n",
              " u'2age15.png',\n",
              " u'2age16.png',\n",
              " u'2age18.png',\n",
              " u'2age20.png',\n",
              " u'2age21.png',\n",
              " u'2age23.png',\n",
              " u'2age26.png',\n",
              " u'2age29.png',\n",
              " u'2age36.png',\n",
              " u'2age38.png',\n",
              " u'2age4.png',\n",
              " u'2age5.png',\n",
              " u'2age7.png']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "composed-things"
      },
      "source": [
        "Then, we create an instance client of the client object in the boto3 package for rekognition. It will allow use to communicate and make requests to the Rekognition service using Python.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eastern-samba"
      },
      "source": [
        "client=boto3.client('rekognition')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "static-nutrition"
      },
      "source": [
        "We import two important package numpy and pandas into the enviroment for later usage, create an empty dataset called df using pd, use boto3 to make an instance of an object s3_resource that will allow us to communicate with S3.\n",
        "and we loop thorugh the summaries bucket and add the images names into the ch dataframe under the column \"Name\"\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "jupyter": {
          "source_hidden": true
        },
        "id": "manufactured-skill",
        "outputId": "a8a7ff87-b98c-4a5c-dd89-7ab515247006"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "ch = pd.DataFrame()\n",
        "s3_resource = boto3.resource('s3')\n",
        "my_bucket = s3_resource.Bucket('image-api-example-finalversion2')\n",
        "summaries = my_bucket.objects.all()\n",
        "image_names = [image.key for image in summaries]\n",
        "ch[\"Name\"] = image_names"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/home/ec2-user/anaconda3/envs/amazonei_mxnet_p27/lib/python2.7/site-packages/boto3/compat.py:86: PythonDeprecationWarning: Boto3 will no longer support Python 2.7 starting July 15, 2021. To continue receiving service updates, bug fixes, and security updates please upgrade to Python 3.6 or later. More information can be found here: https://aws.amazon.com/blogs/developer/announcing-end-of-support-for-python-2-7-in-aws-sdk-for-python-and-aws-cli-v1/\n",
            "  warnings.warn(warning, PythonDeprecationWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "ClientError",
          "evalue": "An error occurred (AccessDenied) when calling the ListObjects operation: Access Denied",
          "traceback": [
            "\u001b[0;31m\u001b[0m",
            "\u001b[0;31mClientError\u001b[0mTraceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-4945fa1ce9d2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmy_bucket\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ms3_resource\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBucket\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'image-api-example-finalversion2'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0msummaries\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmy_bucket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobjects\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mimage_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkey\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mimage\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msummaries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Name\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage_names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/home/ec2-user/anaconda3/envs/amazonei_mxnet_p27/lib/python2.7/site-packages/boto3/resources/collection.pyc\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0mcount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mpage\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpages\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpage\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/home/ec2-user/anaconda3/envs/amazonei_mxnet_p27/lib/python2.7/site-packages/boto3/resources/collection.pyc\u001b[0m in \u001b[0;36mpages\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    164\u001b[0m         \u001b[0;31m# we start processing and yielding individual items.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m         \u001b[0mcount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mpage\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpages\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m             \u001b[0mpage_items\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/home/ec2-user/anaconda3/envs/amazonei_mxnet_p27/lib/python2.7/site-packages/botocore/paginate.pyc\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    253\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inject_starting_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurrent_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 255\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurrent_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m             \u001b[0mparsed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extract_parsed_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mfirst_request\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/home/ec2-user/anaconda3/envs/amazonei_mxnet_p27/lib/python2.7/site-packages/botocore/paginate.pyc\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, current_kwargs)\u001b[0m\n\u001b[1;32m    330\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurrent_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mcurrent_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_extract_parsed_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/home/ec2-user/anaconda3/envs/amazonei_mxnet_p27/lib/python2.7/site-packages/botocore/client.pyc\u001b[0m in \u001b[0;36m_api_call\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    355\u001b[0m                     \"%s() only accepts keyword arguments.\" % py_operation_name)\n\u001b[1;32m    356\u001b[0m             \u001b[0;31m# The \"self\" in this scope is referring to the BaseClient.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 357\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_api_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moperation_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m         \u001b[0m_api_call\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpy_operation_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/home/ec2-user/anaconda3/envs/amazonei_mxnet_p27/lib/python2.7/site-packages/botocore/client.pyc\u001b[0m in \u001b[0;36m_make_api_call\u001b[0;34m(self, operation_name, api_params)\u001b[0m\n\u001b[1;32m    674\u001b[0m             \u001b[0merror_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsed_response\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Error\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Code\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    675\u001b[0m             \u001b[0merror_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_code\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 676\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0merror_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparsed_response\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperation_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    677\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mparsed_response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mClientError\u001b[0m: An error occurred (AccessDenied) when calling the ListObjects operation: Access Denied"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "coupled-influence"
      },
      "source": [
        "We create a list called t_name, and using loop to add the name of the image into the list for later usage"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "environmental-jaguar",
        "outputId": "d142d41e-7df8-439c-f7e0-85b80ffc32b6"
      },
      "source": [
        "t_name = []\n",
        "for photo in images:\n",
        "    t_name.append(photo)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'images' is not defined",
          "traceback": [
            "\u001b[0;31m\u001b[0m",
            "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-3dda99eb68fe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mt_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mphoto\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mt_name\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mphoto\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'images' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "architectural-internet"
      },
      "source": [
        "For this chunk, we first create a constant i = 0 for later usage in the loop.Then we make a loop function. Inside the loop function we define a function called extract_similarity to extract the similarity value for each set using the compare_faces function in the rekognition. After we got the image_score we store it into the ch dataframe and stored it under the column name t_name at the i position.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true,
          "source_hidden": true
        },
        "id": "accredited-dayton",
        "outputId": "88778bb6-fd13-400e-f3e7-2a28c49ec0f8"
      },
      "source": [
        "i = 0\n",
        "for photo in images:\n",
        "    def extract_similarity(image):\n",
        "        try:\n",
        "            comparison = client.compare_faces(SourceImage={'S3Object':{'Bucket':\"image-api-example-finalversion2\",'Name':photo}}, TargetImage={'S3Object':{'Bucket':\"image-api-example-finalversion2\",'Name':image}})\n",
        "            face_match = comparison['FaceMatches']\n",
        "            image_score = face_match[0]['Similarity'] \n",
        "        except:\n",
        "            image_score = np.nan\n",
        "        return image_score\n",
        "    ch[t_name[i]] = [extract_similarity(name) for name in ch[\"Name\"]]\n",
        "    i = i + 1\n",
        "    print(i)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "geographic-event"
      },
      "source": [
        "Define a function called extract_Age to extract the age range value for each image using the detect_faces function in the rekognition."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "anonymous-economics"
      },
      "source": [
        "def extract_age(image):\n",
        "    try:\n",
        "        comparison = client.detect_faces(Image={'S3Object':{'Bucket':\"image-api-example-finalversion2\",'Name':image}}, Attributes = [\"ALL\"])\n",
        "        age_range = comparison[\"FaceDetails\"][0][\"AgeRange\"] \n",
        "    except:\n",
        "        age_range = np.nan\n",
        "    return age_range"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "national-pipeline"
      },
      "source": [
        "After we got the age_range we store it into the ch dataframe and stored it under the column name \"Age_range\".\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "incorporate-jaguar"
      },
      "source": [
        "ch[\"Age_Range\"] = [extract_age(name) for name in ch[\"Name\"]]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "brown-venture"
      },
      "source": [
        "We output the result to a csv file called \"resulsection3.csv\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "genuine-luther"
      },
      "source": [
        "ch.to_csv(\"resultsection3.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wm7hDFWCb9rg"
      },
      "source": [
        "### Results\n",
        "After testing all five data sets we have, we can see that there is a clear trend: the bigger the age difference is, the lower the confidence AWS Rekognition has on if the two pictures are for the same person. As the diagrams below have shown, the further confidence levels locate upper right, the lower the confidence is.\n",
        "\n",
        "![Test Data](https://github.com/AlisiaTian/SP2021QTM350/blob/main/blog/03_2.png?raw=true)\n",
        "\n",
        "So the result is in accordance with our hypothesis, that the AWS Rekognition is able to detect people across different ages and the accuracy decreases after the age difference is too big. The exact benchmark for the age difference is hard to be concluded due to the scale of this project since according to our result, different people display huge disparities in facial difference after a similar time period.\n",
        "\n",
        "![Test Data2](https://github.com/AlisiaTian/SP2021QTM350/blob/main/blog/04.png?raw=true)\n",
        "\n",
        "[insert text]\n",
        "\n",
        "![Visualization](https://github.com/AlisiaTian/SP2021QTM350/blob/main/blog/05.png?raw=true)\n",
        "\n",
        "[Insert text\n",
        "  一段文字（解释上面的图+之前的其它attempt）\n",
        "方向1: 我们尝试做过age cut off, 但是每个人的成长变化率不同，所以很难有个clear standard, 所以做出来的结果不significant\n",
        "方向2: 我们尝试做smiling confidence changes with respect to changes in age，但是这样的dataset非常难找，导致我们的data不够，得不到一个clear result\n",
        "方向3: 我们尝试 identify distinct categories like ‘old man’, ‘man’, ‘young man’, using changes in the similarity score，但是和之前一样，由于每个人成长变化率不一样，导致很难有一个clear standard，所以结果不significant]\n",
        "\n",
        "### Conclusion\n",
        "According to the results, the conclusion is consistent with our initial assumption - although the AWS Rekognition tool can recognize the same person's photo at different ages, the accuracy of detection decreases as the age difference increases. Moreover, we cannot give an exact threshold pass which the accuracy of identification will drop due to individual differences. In sum, although AWS Rekogniton can be useful, as time passes, it will become harder to identify a person.\n",
        "\n",
        "Some improvements can be done. We did not have a large amount of data to determine a certain threshold. Admittedly, accuracy drops as age differences expand, yet it is still important to determine a benchmark pass which will make AWS Rekognition’s result not reliable anymore. Although different people age in various ways, and it is impossible to analyze the difference between individuals, it might be possible to determine a certain threshold for different races or genders with enough graphic data. The drop of accuracy might converge to a certain range of age.\n",
        "\n",
        "To improve the accuracy of our current result and to gain insight into the topic of facial identification better, we need more graphic data of the same individual across their life span. It will be ideal if they are from different backgrounds and ethnic groups, which will improve the diversity of the data set and give more reliable results.\n",
        "\n",
        "\n",
        "### References\n",
        "*Key Facts.* Missingkids.org. (2021). Retrieved 22 April 2021, from https://www.missingkids.org/footer/media/keyfacts.\n",
        "\n",
        "O. H. (2019, September 16). *This Family Took The Same Picture Every Year For Over Two Decades.* TheFashionBall. https://www.thefashionball.com/trends/family-photos-fb/.\n",
        "\n",
        "Ross Reynolds, A. H. (n.d.). *How UW's Age-Progression Software Could Help Find Missing Kids.* KUOW News and Information. http://archive.kuow.org/post/how-uws-age-progression-software-could-help-find-missing-kids.\n",
        "\n",
        "Zhao, W., & Wang, H. (2016). Strategic Decision-Making Learning from Label Distributions: An Approach for Facial Age Estimation. *Sensors*, 16(7), 994. https://doi.org/10.3390/s16070994\n"
      ]
    }
  ]
}
